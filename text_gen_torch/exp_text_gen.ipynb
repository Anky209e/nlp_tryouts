{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import string\n",
    "import numpy\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "all_chars = string.printable\n",
    "n_characters = len(all_chars)\n",
    "\n",
    "file = unidecode.unidecode(open(\"robert_frost.txt\").read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layers,output_size):\n",
    "        super(RNN,self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # Input_size is max no of characters hidden size is dimension of embedding\n",
    "        self.embed = nn.Embedding(input_size,hidden_size) \n",
    "        self.lstm = nn.LSTM(hidden_size,hidden_size,num_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "    \n",
    "    def forward(self,x,hidden,cell):\n",
    "\n",
    "        out = self.embed(x)\n",
    "        out,(hidden,cell) = self.lstm(out.unsqueeze(1),(hidden,cell))\n",
    "        out = self.fc(out.reshape(out.shape[0],-1))\n",
    "\n",
    "        return out,(hidden,cell)\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "\n",
    "        hidden = torch.zeros(self.num_layers,batch_size,self.hidden_size).to(device)\n",
    "        cell = torch.zeros(self.num_layers,batch_size,self.hidden_size).to(device)\n",
    "\n",
    "        return hidden,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self):\n",
    "        self.chunk_len = 250\n",
    "        self.num_epoch = 2000\n",
    "        self.batch_size = 1\n",
    "        self.print_every = 2\n",
    "        self.hidden_size = 250\n",
    "        self.num_layers = 2\n",
    "        self.lr = 0.003\n",
    "        self.rnn = RNN(n_characters,self.hidden_size,self.num_layers,n_characters).to(device)\n",
    "\n",
    "    def char_tensor(self,string):\n",
    "        tensor = torch.zeros(len(string)).long()\n",
    "        for c in range(len(string)):\n",
    "            # Replacing zero with character index\n",
    "            tensor[c] = all_chars.index(string[c])\n",
    "        return tensor\n",
    "    \n",
    "    def get_random_batch(self):\n",
    "        # start index of our random batch\n",
    "        start_idx = random.randint(0,len(file)-self.chunk_len)\n",
    "        # end index of our random batch\n",
    "        end_idx = start_idx + self.chunk_len + 1\n",
    "        # picking text string from file using start and end index\n",
    "        text_str = file[start_idx:end_idx]\n",
    "        text_input = torch.zeros(self.batch_size,self.chunk_len)\n",
    "        text_target = torch.zeros(self.batch_size,self.chunk_len)\n",
    "\n",
    "        # Targets will be next character in sequence since we will be predicting next characters\n",
    "        for i in range(self.batch_size):\n",
    "            text_input[i,:] = self.char_tensor(text_str[:-1])\n",
    "            text_target[i,:] = self.char_tensor(text_str[1:])\n",
    "        \n",
    "        return text_input.long(),text_target.long()\n",
    "\n",
    "    def generate(self,initial_str='A',prediction_len=1000,temprature=0.85):\n",
    "        hidden,cell = self.rnn.init_hidden(self.batch_size)\n",
    "        initial_input = self.char_tensor(initial_str)\n",
    "        predicted = initial_str\n",
    "        \n",
    "        # Handeling LSTM hidden and cell if initial string is longer than 1\n",
    "        for p in range(len(initial_str)-1):\n",
    "            _,(hidden,cell) = self.rnn(initial_input[p].view(1).to(device),hidden,cell)\n",
    "\n",
    "        last_char = initial_input[-1]\n",
    "\n",
    "        for p in range(prediction_len):\n",
    "            output,(hidden,cell) = self.rnn(last_char.view(1).to(device),hidden,cell)\n",
    "            # Handeling temperature for predictions\n",
    "            output_dist = output.data.view(-1).div(temprature).exp()\n",
    "            # Finding characters with highest probs but with a little randomisation too\n",
    "            top_char_probs = torch.multinomial(output_dist,1)\n",
    "            top_char = top_char_probs[0]\n",
    "            # print(top_char)\n",
    "            predicted_char = all_chars[top_char]\n",
    "            predicted+=predicted_char\n",
    "\n",
    "            last_char = self.char_tensor(predicted_char)\n",
    "        print(predicted)\n",
    "        return predicted\n",
    "    \n",
    "    def save_weights(self,filename):\n",
    "        torch.save(self.rnn.state_dict(),filename)\n",
    "    \n",
    "    def load_weights(self,filename):\n",
    "        self.rnn.load_state_dict(torch.load(filename))\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.rnn = RNN(n_characters,self.hidden_size,self.num_layers,n_characters).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.rnn.parameters(),lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"==> Starting Training\")\n",
    "\n",
    "        for epoch in range(1,self.num_epoch+1):\n",
    "            input,target = self.get_random_batch()\n",
    "\n",
    "            hidden,cell = self.rnn.init_hidden(self.batch_size)\n",
    "\n",
    "            self.rnn.zero_grad()\n",
    "            loss = 0\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # providing characters 1 by 1\n",
    "            for c in range(self.chunk_len):\n",
    "                output,(hidden,cell) = self.rnn(input[:,c],hidden,cell)\n",
    "                loss += criterion(output,target[:,c])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss = loss.item()/self.chunk_len\n",
    "\n",
    "            if epoch % self.print_every == 0:\n",
    "                print(f\"===> Epoch:{epoch} ==> Loss:{loss}\")\n",
    "                f_chars = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "                initial_letter = f_chars[random.randint(0,len(f_chars)-1)]\n",
    "                print(f\"-----\\n{self.generate(initial_str=initial_letter)}\\n-----\")\n",
    "        self.save_weights(f\"robert_data_weights_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model_1 = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model_1.load_weights('robert_data_weights_2000.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heyy ankit are, and.\n",
      "I'm it road befort age \n",
      "Harn hope, some say,\n",
      "Up li\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Heyy ankit are, and.\\nI'm it road befort age \\nHarn hope, some say,\\nUp li\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model_1.generate(initial_str='Heyy ankit ',prediction_len=60,temprature=0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
